{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AVICDEBBYH/MAP_CHECK/blob/main/HANA_CLOUD_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "l5qxqamYOXfk",
        "outputId": "0a715a73-37a8-4aaf-ccf0-b38ee840bc3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting generative-ai-hub-sdk\n",
            "  Downloading generative_ai_hub_sdk-4.12.4-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pydantic==2.10.6 (from generative-ai-hub-sdk)\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting overloading==0.5.0 (from generative-ai-hub-sdk)\n",
            "  Downloading overloading-0.5.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from generative-ai-hub-sdk) (8.2.1)\n",
            "Collecting ai-core-sdk>=2.6.2 (from generative-ai-hub-sdk)\n",
            "  Downloading ai_core_sdk-2.6.2-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting dacite>=1.8.1 (from generative-ai-hub-sdk)\n",
            "  Downloading dacite-1.9.2-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from generative-ai-hub-sdk) (25.0)\n",
            "Requirement already satisfied: openai>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from generative-ai-hub-sdk) (1.98.0)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from generative-ai-hub-sdk) (0.28.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.10.6->generative-ai-hub-sdk) (0.7.0)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic==2.10.6->generative-ai-hub-sdk)\n",
            "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.10.6->generative-ai-hub-sdk) (4.14.1)\n",
            "Collecting ai-api-client-sdk==2.6.1 (from ai-core-sdk>=2.6.2->generative-ai-hub-sdk)\n",
            "  Downloading ai_api_client_sdk-2.6.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting aenum~=3.1 (from ai-api-client-sdk==2.6.1->ai-core-sdk>=2.6.2->generative-ai-hub-sdk)\n",
            "  Downloading aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting pyhumps~=3.0 (from ai-api-client-sdk==2.6.1->ai-core-sdk>=2.6.2->generative-ai-hub-sdk)\n",
            "  Downloading pyhumps-3.8.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: requests<3.0 in /usr/local/lib/python3.11/dist-packages (from ai-api-client-sdk==2.6.1->ai-core-sdk>=2.6.2->generative-ai-hub-sdk) (2.32.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->generative-ai-hub-sdk) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->generative-ai-hub-sdk) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->generative-ai-hub-sdk) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->generative-ai-hub-sdk) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->generative-ai-hub-sdk) (0.16.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.58.1->generative-ai-hub-sdk) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.58.1->generative-ai-hub-sdk) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.58.1->generative-ai-hub-sdk) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.58.1->generative-ai-hub-sdk) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0->ai-api-client-sdk==2.6.1->ai-core-sdk>=2.6.2->generative-ai-hub-sdk) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0->ai-api-client-sdk==2.6.1->ai-core-sdk>=2.6.2->generative-ai-hub-sdk) (2.5.0)\n",
            "Downloading generative_ai_hub_sdk-4.12.4-py3-none-any.whl (613 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.6/613.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overloading-0.5.0-py3-none-any.whl (10 kB)\n",
            "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ai_core_sdk-2.6.2-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.7/153.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ai_api_client_sdk-2.6.1-py3-none-any.whl (265 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.5/265.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dacite-1.9.2-py3-none-any.whl (16 kB)\n",
            "Downloading aenum-3.1.16-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.6/165.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyhumps-3.8.0-py3-none-any.whl (6.1 kB)\n",
            "Installing collected packages: pyhumps, overloading, aenum, pydantic-core, dacite, pydantic, ai-api-client-sdk, ai-core-sdk, generative-ai-hub-sdk\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.7\n",
            "    Uninstalling pydantic-2.11.7:\n",
            "      Successfully uninstalled pydantic-2.11.7\n",
            "Successfully installed aenum-3.1.16 ai-api-client-sdk-2.6.1 ai-core-sdk-2.6.2 dacite-1.9.2 generative-ai-hub-sdk-4.12.4 overloading-0.5.0 pydantic-2.10.6 pydantic-core-2.27.2 pyhumps-3.8.0\n",
            "Collecting hdbcli\n",
            "  Downloading hdbcli-2.25.29-cp38-abi3-manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Downloading hdbcli-2.25.29-cp38-abi3-manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hdbcli\n",
            "Successfully installed hdbcli-2.25.29\n",
            "Collecting hana_ml\n",
            "  Downloading hana_ml-2.25.25080800-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: hdbcli>=2.18.22 in /usr/local/lib/python3.11/dist-packages (from hana_ml) (2.25.29)\n",
            "Requirement already satisfied: pydotplus in /usr/local/lib/python3.11/dist-packages (from hana_ml) (2.0.2)\n",
            "Collecting Deprecated (from hana_ml)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.11/dist-packages (from hana_ml) (4.67.1)\n",
            "Collecting schedule (from hana_ml)\n",
            "  Downloading schedule-1.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.11/dist-packages (from hana_ml) (3.16.0)\n",
            "Requirement already satisfied: shapely>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from hana_ml) (2.1.1)\n",
            "Requirement already satisfied: plotly>=4.14.3 in /usr/local/lib/python3.11/dist-packages (from hana_ml) (5.24.1)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.11/dist-packages (from hana_ml) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from hana_ml) (2.2.2)\n",
            "Requirement already satisfied: jinja2>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from hana_ml) (3.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.0->hana_ml) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->hana_ml) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->hana_ml) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->hana_ml) (2025.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.14.3->hana_ml) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=4.14.3->hana_ml) (25.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from Deprecated->hana_ml) (1.17.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable->hana_ml) (0.2.13)\n",
            "Requirement already satisfied: pyparsing>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from pydotplus->hana_ml) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->hana_ml) (1.17.0)\n",
            "Downloading hana_ml-2.25.25080800-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading schedule-1.2.2-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: schedule, Deprecated, hana_ml\n",
            "Successfully installed Deprecated-1.2.18 hana_ml-2.25.25080800 schedule-1.2.2\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install generative-ai-hub-sdk\n",
        "!pip install hdbcli\n",
        "!pip install hana_ml\n",
        "!pip install pandas\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['AICORE_AUTH_URL'] = 'https://avic-subaccount-d2sdwrqf.authentication.jp10.hana.ondemand.com'\n",
        "os.environ['AICORE_CLIENT_ID'] = 'sb-fca69612-5c8f-417b-b9a8-13cb08309fa7!b30307|aicore!b44'\n",
        "os.environ['AICORE_RESOURCE_GROUP'] = 'default'\n",
        "os.environ['AICORE_CLIENT_SECRET'] = 'c6a8afdb-a49b-44a7-a112-1067961e4cf7$B6NA7SnXbpcKL1Bt2myspoEI41ztf8duebAWd47WJrU='\n",
        "os.environ['AICORE_BASE_URL'] = 'https://api.ai.prod.ap-northeast-1.aws.ml.hana.ondemand.com'\n",
        "os.environ['HANA_VECTOR_USER'] = 'DBADMIN'\n",
        "os.environ['HANA_VECTOR_PASS'] = 'Welcome1'\n",
        "os.environ['HANA_HOST_VECTOR'] = 'dabb5e77-369b-4abb-a27c-0db6194e2418.hana.prod-jp10.hanacloud.ondemand.com'"
      ],
      "metadata": {
        "id": "zIXoq996RmK4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"In this scenario, we show how we could use genaihub SDK to retrieve embedded response from SAP HANA Cloud Vector.\n",
        "   WE use two of the foundation models. Based on the use prompt, we use the \"embedding model\" to convert the user prompt\n",
        "   to embedding. We use COSINE SIMILARITY to retrieve the closest embedding from HANA DB. Then the corresponding\n",
        "   text is retrieved along with source file , actual text and Scoring.\n",
        "   Then we provide the retrieved text as input to \"falcon\" model to determine the sentiment of the text.\n",
        "    Please install the necessary packages\n",
        "    pip install   generative-ai-hub-sdk ||hdbcli || hana_ml || python-dotenv || shapely\n",
        "\"\"\"\n",
        "#load all necessary packages\n",
        "from gen_ai_hub.proxy.native.openai import embeddings\n",
        "from gen_ai_hub.proxy.native.openai import completions\n",
        "from gen_ai_hub.proxy.native.openai import chat\n",
        "from  hdbcli import dbapi\n",
        "import pandas as pd\n",
        "import hana_ml.dataframe as dataframe\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "# provide the credentials to connect to HANA Cloud DB\n",
        "HANA_HOST = os.getenv('HANA_HOST_VECTOR')\n",
        "HANA_USER = os.getenv('HANA_VECTOR_USER')\n",
        "HANA_PASSWD = os.getenv('HANA_VECTOR_PASS')\n",
        "# Establish connections\n",
        "conn = dataframe.ConnectionContext(\n",
        "    address= HANA_HOST,\n",
        "    port=443,\n",
        "    user=HANA_USER,\n",
        "    password=HANA_PASSWD,\n",
        "    encrypt='true'\n",
        ")\n",
        "conn1 = dbapi.connect(\n",
        "    address=HANA_HOST,\n",
        "    port=443,\n",
        "    user=HANA_USER,\n",
        "    password=HANA_PASSWD\n",
        ")\n",
        "#Here is the User Prompt. Change it  to query against the text that was ingested\n",
        "prompt = \"請問公司加班規定有哪些？\"\n",
        "#Here we convert your input to vector using the Azure ada embedding model\n",
        "res = embeddings.create(input=prompt, model=\"text-embedding-ada-002\")\n",
        "query_vector = res.data[0].embedding\n",
        "# we query the DB with the embedded response from user prompt\n",
        "sql = '''SELECT TOP {k}  \"FILENAME\",\"CONTENT\" , TO_NVARCHAR(\"EMBEDDING\") AS VECTOR_STR ,\"{metric}\"(\"EMBEDDING\", TO_REAL_VECTOR('{qv}')) as SCORING\n",
        "                  FROM \"VECTOR_DEMO\".\"HR_POLICY_RAG\"\n",
        "                  ORDER BY \"{metric}\"(\"EMBEDDING\", TO_REAL_VECTOR('{qv}')) {sort}'''.format(k=3, metric=\"COSINE_SIMILARITY\", qv=query_vector, sort=\"DESC\")\n",
        "hdf = conn.sql(sql)\n",
        "res = hdf.head(10).collect()\n",
        "#collect the response from previous SQL\n",
        "#NOw loop around every row to get filename, text and data\n",
        "if not res.empty:\n",
        "    db_results = [(row['FILENAME'],row['CONTENT'], row['SCORING']) for _, row in res.iterrows()]\n",
        "    new_results = []\n",
        "    for i in range(len(db_results)):\n",
        "        if i < len(db_results):\n",
        "            filename, text,  scoring = db_results[i]\n",
        "            #we are  getting the sentiment for every text using the below prompt\n",
        "            sentiment_prompt = f\"Provide sentiment in exactly one word for the: '{text}'\"\n",
        "            #in order to get the prompt we call the falcon model from aicore config\n",
        "            # sentiment_output = completions.create(model_name=\"gpt-35-turbo\", prompt=sentiment_prompt, max_tokens=60)\n",
        "            # sentiment = sentiment_output.choices[0].text.strip()\n",
        "\n",
        "            messages = [ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": sentiment_prompt} ]\n",
        "\n",
        "            print(sentiment_prompt)\n",
        "\n",
        "            kwargs = dict(model_name='gpt-35-turbo', messages=messages)\n",
        "            response = chat.completions.create(**kwargs)\n",
        "            # sentiment = response['choices'][0]['message']['content'].strip()\n",
        "            sentiment = response.choices[0].message.content.strip()\n",
        "\n",
        "            print(sentiment)\n",
        "\n",
        "            new_tuple =  (filename,text, scoring, sentiment)\n",
        "            new_results.append(new_tuple)\n",
        "#transform the results to DF and check the output\n",
        "df_new_results = pd.DataFrame(new_results)\n",
        "print(df_new_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuhsEIF2Xk77",
        "outputId": "042c323c-5af3-48b5-ce6a-b44618875ff6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Provide sentiment in exactly one word for the: '第三十八條：本公司因業務需求，員工有於正常工作時間以外工作之必要\n",
            "者，由單位主管與員工商議後：\n",
            "一、得將本規則第三十四條所定之工作時間延長之。\n",
            "二、得於休假日工作。'\n",
            "Necessary\n",
            "Provide sentiment in exactly one word for the: '第三十五條：前條所訂工作時間，經員工半數以上同意得做下列變更：\n",
            "一、四週內正常工作時數以每日不得超過二小時方式，分配\n",
            "於其他工作日。\n",
            "第 5 頁\n",
            "--- 頁9 ---\n",
            "二、當日正常工時達十小時者，其延長之工作時間不得超過\n",
            "二小時。\n",
            "三、兩週內應有二日之休息作為例假。\n",
            "四、女性員工得於夜間工作，但雇主應提供完善安全衛生設\n",
            "施。'\n",
            "Neutral\n",
            "Provide sentiment in exactly one word for the: '第三十四條：加班費之計算，優於勞基法以月薪除上22天為日薪，其他倍\n",
            "率計算以勞工局規範為準。\n",
            "第 五 章 工 作 時 間 、 休 息 、 休 假 、 請 假\n",
            "第 一 節 工 作 時 間'\n",
            "Neutral\n",
            "                    0                                                  1  \\\n",
            "0  艾威科人事管理規則 2022.pdf  第三十八條：本公司因業務需求，員工有於正常工作時間以外工作之必要\\n者，由單位主管與員工商議...   \n",
            "1  艾威科人事管理規則 2022.pdf  第三十五條：前條所訂工作時間，經員工半數以上同意得做下列變更：\\n一、四週內正常工作時數以每...   \n",
            "2  艾威科人事管理規則 2022.pdf  第三十四條：加班費之計算，優於勞基法以月薪除上22天為日薪，其他倍\\n率計算以勞工局規範為準...   \n",
            "\n",
            "          2          3  \n",
            "0  0.878344  Necessary  \n",
            "1  0.870861    Neutral  \n",
            "2  0.867536    Neutral  \n"
          ]
        }
      ]
    }
  ]
}